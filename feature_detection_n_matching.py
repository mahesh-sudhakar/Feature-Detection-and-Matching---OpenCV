# -*- coding: utf-8 -*-
"""AER1515_Ass01.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1n-F7fM9tux4MvUbWo3OvA2ABJN5UHMtq
"""

import numpy as np
import pandas as pd
import cv2 as cv
import matplotlib.pyplot as plt
import os
import csv
import math

#from google.colab import drive
#drive.mount('/content/drive')

class FrameCalib:
    """Frame Calibration

    Fields:
        p0-p3: (3, 4) Camera P matrices for cameras 0-3. Combines extrinsic and intrinsic parameters.
        r0_rect: (3, 3) Rectification matrix
        velo_to_cam: (3, 4) Transformation matrix from velodyne to cam coordinates
        Point_Camera = p_cam * r0_rect * Tr_velo_to_cam * Point_Velodyne
        """

    def __init__(self):
        self.p0 = []
        self.p1 = []
        self.p2 = []
        self.p3 = []
        self.r0_rect = []
        self.velo_to_cam = []


def read_frame_calib(calib_file_path):
    """Reads the calibration file for a sample

    Args:
        calib_file_path: calibration file path

    Returns:
        frame_calib: FrameCalib frame calibration
    """

    data_file = open(calib_file_path, 'r')
    data_reader = csv.reader(data_file, delimiter=' ')
    data = []

    for row in data_reader:
        data.append(row)

    data_file.close()

    p_all = []

    for i in range(4):
        p = data[i]
        p = p[1:]
        p = [float(p[i]) for i in range(len(p))]
        p = np.reshape(p, (3, 4))
        p_all.append(p)

    frame_calib = FrameCalib()
    frame_calib.p0 = p_all[0]
    frame_calib.p1 = p_all[1]
    frame_calib.p2 = p_all[2]
    frame_calib.p3 = p_all[3]

    # Read in rectification matrix
    tr_rect = data[4]
    tr_rect = tr_rect[1:]
    tr_rect = [float(tr_rect[i]) for i in range(len(tr_rect))]
    frame_calib.r0_rect = np.reshape(tr_rect, (3, 3))

    # Read in velodyne to cam matrix
    tr_v2c = data[5]
    tr_v2c = tr_v2c[1:]
    tr_v2c = [float(tr_v2c[i]) for i in range(len(tr_v2c))]
    frame_calib.velo_to_cam = np.reshape(tr_v2c, (3, 4))

    return frame_calib

class StereoCalib:
    """Stereo Calibration

    Fields:
        baseline: distance between the two camera centers
        f: focal length
        k: (3, 3) intrinsic calibration matrix
        p: (3, 4) camera projection matrix
        center_u: camera origin u coordinate
        center_v: camera origin v coordinate
        """

    def __init__(self):
        self.baseline = 0.0
        self.f = 0.0
        self.k = []
        self.center_u = 0.0
        self.center_v = 0.0


def krt_from_p(p, fsign=1):
    """Factorize the projection matrix P as P=K*[R;t]
    and enforce the sign of the focal length to be fsign.


    Keyword Arguments:
    ------------------
    p : 3x4 list
        Camera Matrix.

    fsign : int
            Sign of the focal length.


    Returns:
    --------
    k : 3x3 list
        Intrinsic calibration matrix.

    r : 3x3 list
        Extrinsic rotation matrix.

    t : 1x3 list
        Extrinsic translation.
    """
    s = p[0:3, 3]
    q = np.linalg.inv(p[0:3, 0:3])
    u, b = np.linalg.qr(q)
    sgn = np.sign(b[2, 2])
    b = b * sgn
    s = s * sgn

    # If the focal length has wrong sign, change it
    # and change rotation matrix accordingly.
    if fsign * b[0, 0] < 0:
        e = [[-1, 0, 0], [0, 1, 0], [0, 0, 1]]
        b = np.matmul(e, b)
        u = np.matmul(u, e)

    if fsign * b[2, 2] < 0:
        e = [[1, 0, 0], [0, -1, 0], [0, 0, 1]]
        b = np.matmul(e, b)
        u = np.matmul(u, e)

    # If u is not a rotation matrix, fix it by flipping the sign.
    if np.linalg.det(u) < 0:
        u = -u
        s = -s

    r = np.matrix.transpose(u)
    t = np.matmul(b, s)
    k = np.linalg.inv(b)
    k = k / k[2, 2]

    # Sanity checks to ensure factorization is correct
    if np.linalg.det(r) < 0:
        print('Warning: R is not a rotation matrix.')

    if k[2, 2] < 0:
        print('Warning: K has a wrong sign.')

    return k, r, t


def get_stereo_calibration(left_cam_mat, right_cam_mat):
    """Extract parameters required to transform disparity image to 3D point
    cloud.

    Keyword Arguments:
    ------------------
    left_cam_mat : 3x4 list
                   Left Camera Matrix.

    right_cam_mat : 3x4 list
                   Right Camera Matrix.


    Returns:
    --------
    stereo_calibration_info : Instance of StereoCalibrationData class
                              Placeholder for stereo calibration parameters.
    """

    stereo_calib = StereoCalib()
    k_left, r_left, t_left = krt_from_p(left_cam_mat)
    _, _, t_right = krt_from_p(right_cam_mat)

    stereo_calib.baseline = abs(t_left[0] - t_right[0])
    stereo_calib.f = k_left[0, 0]
    stereo_calib.k = k_left
    stereo_calib.center_u = k_left[0, 2]
    stereo_calib.center_v = k_left[1, 2]

    return stereo_calib

# function definition for detecting features
def feature_detection(img_name):
    img = cv.imread(os.path.join(dataset_path, img_name))
    rgb_img = cv.cvtColor(img, cv.COLOR_BGR2RGB)
    gray_img = cv.cvtColor(rgb_img, cv.COLOR_RGB2GRAY)

    kp, des = orb.detectAndCompute(gray_img, None)
    return rgb_img, gray_img, kp, des

# function definition for feature matching between images
def feature_matching(left_img, right_img):
    rgb_img_l, gray_img_l, kp_l, des_l = feature_detection(left_img)
    rgb_img_r, gray_img_r, kp_r, des_r = feature_detection(right_img)

    kp_wo_size = np.copy(rgb_img_l)
    kp_w_size = np.copy(rgb_img_l)

    cv.drawKeypoints(rgb_img_l, kp_l, kp_wo_size, color=(0, 255, 0))
    cv.drawKeypoints(rgb_img_l, kp_l, kp_w_size, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)

    print("\n New Image:")

    fx, plots = plt.subplots(1, 2, figsize=(16, 10))

    plots[0].set_title("Left image - keypoints with size")
    plots[0].imshow(kp_w_size, cmap='gray')

    plots[1].set_title("Left image - keypoints without size")
    plots[1].imshow(kp_wo_size, cmap='gray')
    plt.show()    

    print("Number of keypoints detected in the left image: ", len(kp_l))
    print("Number of keypoints detected in the right image: ", len(kp_r))
        
    bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)
    matches = bf.match(des_l, des_r)
    matches = sorted(matches, key = lambda x: x.distance) 

    numGoodMatches = int(len(matches) * GOOD_MATCH_PERCENT)
    top_matches = matches[:numGoodMatches]

    img_matches = cv.drawMatches(rgb_img_l, kp_l, rgb_img_r, kp_r, top_matches, None, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)
    plt.figure(figsize=(16, 16))
    plt.title('Best Matching Points')
    plt.imshow(img_matches)
    plt.show()

    print("\n Number of matching keypoints between the left and right images: ", len(matches))
    print("\n Matches displayed: ", len(top_matches))
    
    return rgb_img_l, gray_img_l, kp_l, des_l, rgb_img_r, gray_img_r, kp_r, des_r, matches

n_features = 1000
GOOD_MATCH_PERCENT = 1    
orb = cv.ORB_create(n_features)

dataset_path = 'R:/UofT OneDrive/OneDrive - University of Toronto/ECE/Fall 19/Perception/assignment/1/test/'                #paste_path_here

## Input
left_image_dir = 'R:/UofT OneDrive/OneDrive - University of Toronto/ECE/Fall 19/Perception/assignment/1/test/left/'         #paste_path_here
right_image_dir = 'R:/UofT OneDrive/OneDrive - University of Toronto/ECE/Fall 19/Perception/assignment/1/test/right/'       #paste_path_here
calib_dir = 'R:/UofT OneDrive/OneDrive - University of Toronto/ECE/Fall 19/Perception/assignment/1/test/calib/'             #paste_path_here
sample_list = ['000011' , '000012', '000013', '000014','000015']                              #change_sample_list

## Output
output_file = open("P3_result.txt", "a")
output_file.truncate(0)

## Main

# for each sample in the list
for sample_name in sample_list:

  #initialize arrays
  points_l = []
  points_r = []
  pixel_u_list = []
  pixel_v_list = []
  disparity_list = []
  depth_list = []

  #create object for FrameCalib class
  calib_obj = FrameCalib()
  calib_obj = read_frame_calib('R:/UofT OneDrive/OneDrive - University of Toronto/ECE/Fall 19/Perception/assignment/1/test/calib/'+sample_name+'.txt')       #paste_path_here

  #create object for StereoCalib class
  stereo_obj = StereoCalib()
  stereo_obj = get_stereo_calibration(calib_obj.p2, calib_obj.p3)

  fB = stereo_obj.baseline*stereo_obj.f
  
  rgb_img_l, gray_img_l, kp_l, des_l, rgb_img_r, gray_img_r, kp_r, des_r, matches = feature_matching('left/'+sample_name+'.png', 'right/'+sample_name+'.png')

  horizontal_matches = matches.copy()
  mat = 0
  while mat < len(horizontal_matches):
    if (kp_l[horizontal_matches[mat].queryIdx].pt)[1] != (kp_r[horizontal_matches[mat].trainIdx].pt)[1]:
      del horizontal_matches[mat]
    else:
        mat += 1

  hor_matches = cv.drawMatches(rgb_img_l, kp_l, rgb_img_r, kp_r, horizontal_matches, 
                             None, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)
  plt.figure(figsize=(16, 16))
  plt.title('Horizontal matches')
  plt.imshow(hor_matches)
  plt.show()
  print("No. of horizontal matches found : ", len(horizontal_matches))

  #RANSAC implementation
  points1 = np.zeros((len(matches), 2), dtype=np.float32)
  points2 = np.zeros((len(matches), 2), dtype=np.float32)

  for i, match in enumerate(matches):
      points1[i, :] = kp_l[match.queryIdx].pt
      points2[i, :] = kp_r[match.trainIdx].pt

  h, status = cv.findHomography(points1, points2, cv.RANSAC, 
                                ransacReprojThreshold = 7, maxIters=1600, confidence = 0.99) 
  matchesMask = status.ravel().tolist()

  ransac_count = 0
  outliers = 0
  for i in range(len(matchesMask)):
      if matchesMask[i] == 1:
          ransac_count += 1
      else:
          outliers +=1

  draw_params = dict(singlePointColor = None,
                   matchesMask = matchesMask, # draw only inliers
                   flags = 2)
  
  ransac_matches = cv.drawMatches(rgb_img_l, kp_l, rgb_img_r, kp_r,matches,None,**draw_params)
  plt.figure(figsize=(16, 16))
  plt.title('Ransac_matches')
  plt.imshow(ransac_matches)
  plt.show()
  print("No. of inliers after RANSAC :", ransac_count)
  print("No. of outliers rejected :", outliers)
  print("\n")
  
  for match in matches:
    (x1, y1) = kp_l[match.queryIdx].pt
    (x2, y2) = kp_r[match.trainIdx].pt

    points_l.append((x1, y1))
    points_r.append((x2, y2))

  #calculate disparity and depth
  print("fB : ", fB)
  for i in range(len(points_l)):
    x, y = points_l[i]
    pixel_u_list.append(x)
    pixel_v_list.append(y)

    disparity = points_l[i][0] - points_r[i][0]
    disparity_list.append(disparity)
    
    depth = fB/disparity
    depth_list.append(depth)

  for u, v, disp, depth in zip(pixel_u_list, pixel_v_list, disparity_list, depth_list):
          line = "{} {:.2f} {:.2f} {:.2f} {:.2f}".format(sample_name, u, v, disp, depth)
          output_file.write(line + '\n')


print("\n\n\n P3_result.txt file created")
output_file.close()